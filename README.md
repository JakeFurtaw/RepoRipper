# Repo Ripper

Repo Ripper is an innovative tool designed to revolutionize the way developers interact with and understand GitHub repositories, especially when dealing with unfamiliar codebases or languages. This efficient, locally-run application allows users to have intelligent conversations about any GitHub repository's contents using advanced Language Model (LLM) technology.

## Key Features:

1. **GitHub Integration**: Seamlessly connects to any public GitHub repository, allowing users to specify the owner, repo name, and branch.

2. **Flexible File Filtering**: Users can target specific file extensions, focusing the analysis on relevant code files.

3. **Local LLM Powered**: Utilizes Ollama's Codestral model, running entirely on your local machine, eliminating the need for costly API subscriptions.

4. **Dual Interaction Modes**:
   - Query Engine: For quick, specific questions about the repository.
   - Chat Engine: Maintains conversation history for more context-aware interactions.

5. **Advanced NLP Techniques**: Implements Retrieval-Augmented Generation (RAG) to provide accurate, context-based responses.

6. **Customizable Prompts**: Includes carefully crafted prompts to guide the LLM in providing relevant and precise answers.

7. **Efficient Embedding**: Uses HuggingFace's BGE embeddings for optimal performance in understanding code context.

8. **GPU Acceleration**: Supports CUDA for enhanced processing speed on compatible hardware.

## Use Cases:

- Quickly understand new codebases or projects written in unfamiliar languages.
- Generate boilerplate or repetitive code snippets based on existing repository patterns.
- Get explanations or summaries of complex code structures or algorithms within a repository.
- Assist in code reviews by providing context and explanations for specific parts of the codebase.

Repo Ripper stands out as a powerful tool for developers, researchers, and code reviewers, offering a unique way to interact with and extract insights from GitHub repositories. By leveraging the power of local LLMs, it provides a cost-effective, privacy-conscious alternative to cloud-based code analysis tools.
